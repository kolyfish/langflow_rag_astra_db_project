#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•´åˆ Astra DB èˆ‡ç¾æœ‰ Langflow æµç¨‹
å°‡æ‚¨çš„ Astra DB èˆ‡ç¾æœ‰çš„ Vector Store RAG æµç¨‹çµåˆ
"""

import json
import os
import asyncio
from typing import Dict, Any, List
from pathlib import Path

# æ‚¨çš„ API é‡‘é‘° - è«‹å¾ç’°å¢ƒè®Šæ•¸æˆ– .env æª”æ¡ˆä¸­è®€å–
GROK_API_KEY = os.getenv("GROK_API_KEY", "YOUR_GROK_API_KEY_HERE")
CHATGPT_API_KEY = os.getenv("OPENAI_API_KEY", "YOUR_OPENAI_API_KEY_HERE")
ASTRA_DB_ID = "ef4581e5-f997-44ce-8432-e56636786548"

class LangflowAstraIntegrator:
    """Langflow èˆ‡ Astra DB æ•´åˆå™¨"""
    
    def __init__(self):
        self.original_flow_path = r"c:\Users\WUYUEH\Documents\langflow\Vector Store RAG.json"
        self.enhanced_flow_path = "examples/enhanced-astra-rag-flow.json"
        
    def load_original_flow(self) -> Dict[str, Any]:
        """è¼‰å…¥åŸå§‹ Langflow æµç¨‹"""
        try:
            with open(self.original_flow_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"âŒ è¼‰å…¥åŸå§‹æµç¨‹å¤±æ•—: {e}")
            return {}
    
    def create_astra_vector_store_config(self) -> Dict[str, Any]:
        """å‰µå»º Astra DB Vector Store é…ç½®"""
        return {
            "id": "AstraVectorStore-astra1",
            "type": "AstraVectorStore",
            "position": {"x": 400, "y": 300},
            "data": {
                "label": "Astra DB Vector Store",
                "database_id": ASTRA_DB_ID,
                "collection_name": "langflow_documents",
                "embedding_dimension": 1536,
                "metric": "cosine",
                "api_endpoint": f"https://{ASTRA_DB_ID}-us-east1.apps.astra.datastax.com",
                "region": "us-east1",
                "provider": "gcp"
            }
        }
    
    def create_enhanced_flow(self) -> Dict[str, Any]:
        """å‰µå»ºå¢å¼·ç‰ˆæµç¨‹ï¼Œæ•´åˆ Astra DB"""
        original_flow = self.load_original_flow()
        if not original_flow:
            return {}
        
        # å‰µå»ºæ–°çš„æµç¨‹é…ç½®
        enhanced_flow = {
            "name": "Enhanced Astra DB RAG Flow",
            "description": "æ•´åˆ Astra DB çš„å¢å¼·ç‰ˆ RAG æµç¨‹ï¼Œæ”¯æ´å¤šå€‹ LLM å’Œå‘é‡å­˜å„²",
            "data": {
                "nodes": [],
                "edges": []
            }
        }
        
        # æ·»åŠ è¼¸å…¥ç¯€é»
        input_node = {
            "id": "ChatInput-enhanced",
            "type": "ChatInput",
            "position": {"x": 100, "y": 100},
            "data": {
                "label": "ç”¨æˆ¶è¼¸å…¥",
                "placeholder": "è«‹è¼¸å…¥æ‚¨çš„å•é¡Œ...",
                "multiline": True
            }
        }
        
        # æ·»åŠ  Astra DB Vector Store ç¯€é»
        astra_vector_store = self.create_astra_vector_store_config()
        
        # æ·»åŠ  Grok LLM ç¯€é»
        grok_llm = {
            "id": "GrokLLM-grok1",
            "type": "GrokLLM",
            "position": {"x": 800, "y": 200},
            "data": {
                "label": "Grok AI è™•ç†å™¨",
                "api_key": GROK_API_KEY,
                "model": "grok-beta",
                "temperature": 0.7,
                "max_tokens": 1000,
                "system_message": "ä½ æ˜¯ä¸€å€‹åŸºæ–¼ Astra DB çŸ¥è­˜åº«çš„æ™ºèƒ½åŠ©æ‰‹ï¼Œè«‹æ ¹æ“šæä¾›çš„ä¸Šä¸‹æ–‡å›ç­”ç”¨æˆ¶å•é¡Œã€‚"
            }
        }
        
        # æ·»åŠ  ChatGPT ç¯€é»
        chatgpt_llm = {
            "id": "OpenAIChat-chatgpt1",
            "type": "OpenAIChat",
            "position": {"x": 800, "y": 400},
            "data": {
                "label": "ChatGPT è™•ç†å™¨",
                "api_key": CHATGPT_API_KEY,
                "model": "gpt-3.5-turbo",
                "temperature": 0.7,
                "max_tokens": 1000,
                "system_message": "ä½ æ˜¯ä¸€å€‹åŸºæ–¼ Astra DB çŸ¥è­˜åº«çš„æ™ºèƒ½åŠ©æ‰‹ï¼Œè«‹æ ¹æ“šæä¾›çš„ä¸Šä¸‹æ–‡å›ç­”ç”¨æˆ¶å•é¡Œã€‚"
            }
        }
        
        # æ·»åŠ è¼¸å‡ºç¯€é»
        output_node = {
            "id": "ChatOutput-enhanced",
            "type": "ChatOutput",
            "position": {"x": 1200, "y": 300},
            "data": {
                "label": "AI å›ç­”è¼¸å‡º"
            }
        }
        
        # æ·»åŠ è·¯ç”±ç¯€é»ï¼ˆé¸æ“‡ä½¿ç”¨å“ªå€‹ LLMï¼‰
        router_node = {
            "id": "Router-llm_selector",
            "type": "Router",
            "position": {"x": 600, "y": 300},
            "data": {
                "label": "LLM é¸æ“‡å™¨",
                "routing_key": "llm_preference",
                "routes": {
                    "grok": "GrokLLM-grok1",
                    "chatgpt": "OpenAIChat-chatgpt1"
                }
            }
        }
        
        # çµ„è£ç¯€é»
        enhanced_flow["data"]["nodes"] = [
            input_node,
            astra_vector_store,
            router_node,
            grok_llm,
            chatgpt_llm,
            output_node
        ]
        
        # æ·»åŠ é€£æ¥ç·š
        enhanced_flow["data"]["edges"] = [
            {
                "id": "edge-input-to-vector",
                "source": "ChatInput-enhanced",
                "target": "AstraVectorStore-astra1",
                "sourceHandle": "message",
                "targetHandle": "query"
            },
            {
                "id": "edge-vector-to-router",
                "source": "AstraVectorStore-astra1",
                "target": "Router-llm_selector",
                "sourceHandle": "documents",
                "targetHandle": "input"
            },
            {
                "id": "edge-router-to-grok",
                "source": "Router-llm_selector",
                "target": "GrokLLM-grok1",
                "sourceHandle": "grok",
                "targetHandle": "input"
            },
            {
                "id": "edge-router-to-chatgpt",
                "source": "Router-llm_selector",
                "target": "OpenAIChat-chatgpt1",
                "sourceHandle": "chatgpt",
                "targetHandle": "input"
            },
            {
                "id": "edge-grok-to-output",
                "source": "GrokLLM-grok1",
                "target": "ChatOutput-enhanced",
                "sourceHandle": "output",
                "targetHandle": "input"
            },
            {
                "id": "edge-chatgpt-to-output",
                "source": "OpenAIChat-chatgpt1",
                "target": "ChatOutput-enhanced",
                "sourceHandle": "output",
                "targetHandle": "input"
            }
        ]
        
        return enhanced_flow
    
    def create_astra_setup_script(self) -> str:
        """å‰µå»º Astra DB è¨­ç½®è…³æœ¬"""
        return '''#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Astra DB è¨­ç½®è…³æœ¬
ç‚º Langflow æµç¨‹æº–å‚™ Astra DB æ•¸æ“š
"""

import asyncio
import json
from astrapy import DataAPIClient
from openai import OpenAI

# é…ç½®
ASTRA_DB_ID = "ef4581e5-f997-44ce-8432-e56636786548"
CHATGPT_API_KEY = os.getenv("OPENAI_API_KEY", "YOUR_OPENAI_API_KEY_HERE")

async def setup_astra_for_langflow():
    """ç‚º Langflow è¨­ç½® Astra DB"""
    print("ğŸš€ è¨­ç½® Astra DB ç”¨æ–¼ Langflow")
    print("=" * 50)
    
    # ç²å– API Token
    token = input("è«‹è¼¸å…¥æ‚¨çš„ Astra DB API Token: ").strip()
    if not token:
        print("âŒ éœ€è¦æä¾› API Token")
        return
    
    try:
        # é€£æ¥åˆ° Astra DB
        client = DataAPIClient(token)
        database = client.get_database(ASTRA_DB_ID)
        
        # å‰µå»ºé›†åˆ
        collection_name = "langflow_documents"
        print(f"ğŸ“¦ å‰µå»ºé›†åˆ: {collection_name}")
        
        collection = await database.create_collection(
            collection_name,
            dimension=1536,  # OpenAI åµŒå…¥ç¶­åº¦
            metric="cosine"
        )
        
        # è¨­ç½® OpenAI å®¢æˆ¶ç«¯
        openai_client = OpenAI(api_key=CHATGPT_API_KEY)
        
        # ç¯„ä¾‹æ–‡æª”
        sample_docs = [
            {
                "text": "Langflow æ˜¯ä¸€å€‹é–‹æºçš„ AI æµç¨‹è‡ªå‹•åŒ–å¹³å°ï¼Œå¯ä»¥å¹«åŠ©ç”¨æˆ¶å‰µå»ºè¤‡é›œçš„ AI å·¥ä½œæµç¨‹ã€‚",
                "metadata": {"source": "langflow_docs", "category": "introduction"},
                "timestamp": "2024-01-01T00:00:00Z"
            },
            {
                "text": "Astra DB æ˜¯ DataStax æä¾›çš„å‘é‡æ•¸æ“šåº«æœå‹™ï¼Œå°ˆç‚º AI æ‡‰ç”¨è¨­è¨ˆï¼Œæ”¯æ´é«˜æ•ˆçš„å‘é‡æœç´¢ã€‚",
                "metadata": {"source": "astra_docs", "category": "database"},
                "timestamp": "2024-01-01T00:00:00Z"
            },
            {
                "text": "RAG (Retrieval-Augmented Generation) æ˜¯ä¸€ç¨®çµåˆæª¢ç´¢å’Œç”Ÿæˆçš„ AI æŠ€è¡“ï¼Œå¯ä»¥æé«˜å›ç­”çš„æº–ç¢ºæ€§ã€‚",
                "metadata": {"source": "ai_research", "category": "technique"},
                "timestamp": "2024-01-01T00:00:00Z"
            }
        ]
        
        # ç‚ºæ–‡æª”ç”ŸæˆåµŒå…¥å‘é‡
        print("ğŸ”„ ç”ŸæˆåµŒå…¥å‘é‡...")
        for doc in sample_docs:
            response = openai_client.embeddings.create(
                model="text-embedding-3-small",
                input=doc["text"]
            )
            doc["$vector"] = response.data[0].embedding
        
        # æ’å…¥æ–‡æª”
        print("ğŸ“ æ’å…¥æ–‡æª”åˆ° Astra DB...")
        result = await collection.insert_many(sample_docs)
        print(f"âœ… æˆåŠŸæ’å…¥ {len(sample_docs)} å€‹æ–‡æª”")
        
        print("ğŸ‰ Astra DB è¨­ç½®å®Œæˆï¼")
        print("ç¾åœ¨æ‚¨å¯ä»¥åœ¨ Langflow ä¸­ä½¿ç”¨é€™å€‹å‘é‡æ•¸æ“šåº«äº†ã€‚")
        
    except Exception as e:
        print(f"âŒ è¨­ç½®å¤±æ•—: {e}")

if __name__ == "__main__":
    asyncio.run(setup_astra_for_langflow())
'''
    
    def save_enhanced_flow(self):
        """ä¿å­˜å¢å¼·ç‰ˆæµç¨‹"""
        enhanced_flow = self.create_enhanced_flow()
        if enhanced_flow:
            with open(self.enhanced_flow_path, 'w', encoding='utf-8') as f:
                json.dump(enhanced_flow, f, ensure_ascii=False, indent=2)
            print(f"âœ… å¢å¼·ç‰ˆæµç¨‹å·²ä¿å­˜åˆ°: {self.enhanced_flow_path}")
            return True
        return False
    
    def create_usage_guide(self) -> str:
        """å‰µå»ºä½¿ç”¨æŒ‡å—"""
        return r"""
# ğŸš€ Astra DB + Langflow æ•´åˆä½¿ç”¨æŒ‡å—

## ğŸ“‹ æ‚¨ç¾æœ‰çš„è³‡æº
- âœ… Astra DB ID: ef4581e5-f997-44ce-8432-e56636786548
- âœ… Grok API Key: å·²é…ç½®
- âœ… ChatGPT API Key: å·²é…ç½®
- âœ… åŸå§‹ Langflow RAG æµç¨‹: Vector Store RAG.json

## ğŸ”§ è¨­ç½®æ­¥é©Ÿ

### 1. å®‰è£ä¾è³´å¥—ä»¶
```bash
# å®‰è£ Astra DB ç›¸é—œå¥—ä»¶
.\uv-plugin-manager.ps1 -Action install -Package astrapy
.\uv-plugin-manager.ps1 -Action install -Package openai
```

### 2. è¨­ç½® Astra DB
```bash
# é‹è¡Œè¨­ç½®è…³æœ¬
python setup-astra-for-langflow.py
```

### 3. å°å…¥å¢å¼·ç‰ˆæµç¨‹
1. æ‰“é–‹ Langflow ç•Œé¢
2. é»æ“Š "Import Flow"
3. é¸æ“‡ `examples/enhanced-astra-rag-flow.json`

## ğŸ¯ æ–°åŠŸèƒ½ç‰¹è‰²

### é›™ LLM æ”¯æ´
- **Grok AI**: ç”¨æ–¼å‰µæ„æ€§å’Œåˆ†ææ€§å•é¡Œ
- **ChatGPT**: ç”¨æ–¼ä¸€èˆ¬æ€§å•ç­”å’ŒæŠ€è¡“å•é¡Œ

### Astra DB é›†æˆ
- è‡ªå‹•å‘é‡æœç´¢
- èªç¾©ç›¸ä¼¼æ€§åŒ¹é…
- å¯æ“´å±•çš„çŸ¥è­˜åº«

### æ™ºèƒ½è·¯ç”±
- æ ¹æ“šå•é¡Œé¡å‹é¸æ“‡æœ€é©åˆçš„ LLM
- è‡ªå‹•ä¸Šä¸‹æ–‡æ§‹å»º
- å¤šæºçŸ¥è­˜æ•´åˆ

## ğŸ” ä½¿ç”¨ç¯„ä¾‹

### å•ç­”æ¸¬è©¦
- "ä»€éº¼æ˜¯ Langflowï¼Ÿ" â†’ ä½¿ç”¨ ChatGPT
- "åˆ†æ AI çš„æœªä¾†è¶¨å‹¢" â†’ ä½¿ç”¨ Grok AI
- "å¦‚ä½•è¨­ç½®å‘é‡æ•¸æ“šåº«ï¼Ÿ" â†’ ä½¿ç”¨ ChatGPT

### çŸ¥è­˜åº«æŸ¥è©¢
- è‡ªå‹•å¾ Astra DB æª¢ç´¢ç›¸é—œæ–‡æª”
- çµåˆå¤šå€‹ LLM çš„å„ªå‹¢
- æä¾›æº–ç¢ºä¸”è©³ç´°çš„å›ç­”

## ğŸ“Š ç›£æ§å’Œå„ªåŒ–

### æ€§èƒ½æŒ‡æ¨™
- æœç´¢éŸ¿æ‡‰æ™‚é–“
- LLM é¸æ“‡æº–ç¢ºæ€§
- ç”¨æˆ¶æ»¿æ„åº¦

### å„ªåŒ–å»ºè­°
- å®šæœŸæ›´æ–°çŸ¥è­˜åº«
- èª¿æ•´ LLM åƒæ•¸
- ç›£æ§ API ä½¿ç”¨é‡

## ğŸ†˜ æ•…éšœæ’é™¤

### å¸¸è¦‹å•é¡Œ
1. **Astra DB é€£æ¥å¤±æ•—**: æª¢æŸ¥ API Token
2. **LLM ç„¡éŸ¿æ‡‰**: é©—è­‰ API Key
3. **æœç´¢çµæœä¸æº–ç¢º**: èª¿æ•´åµŒå…¥æ¨¡å‹åƒæ•¸

### æ”¯æ´è³‡æº
- Langflow æ–‡æª”: https://docs.langflow.org/
- Astra DB æ–‡æª”: https://docs.datastax.com/en/astra/
- æœ¬å°ˆæ¡ˆæ–‡æª”: examples/README.md
"""

def main():
    """ä¸»ç¨‹å¼"""
    print("ğŸ”— æ•´åˆ Astra DB èˆ‡ç¾æœ‰ Langflow æµç¨‹")
    print("=" * 60)
    
    integrator = LangflowAstraIntegrator()
    
    # å‰µå»ºå¢å¼·ç‰ˆæµç¨‹
    print("ğŸ“ å‰µå»ºå¢å¼·ç‰ˆæµç¨‹...")
    if integrator.save_enhanced_flow():
        print("âœ… å¢å¼·ç‰ˆæµç¨‹å‰µå»ºæˆåŠŸ")
    else:
        print("âŒ å¢å¼·ç‰ˆæµç¨‹å‰µå»ºå¤±æ•—")
        return
    
    # å‰µå»ºè¨­ç½®è…³æœ¬
    print("ğŸ“ å‰µå»º Astra DB è¨­ç½®è…³æœ¬...")
    setup_script = integrator.create_astra_setup_script()
    with open("setup-astra-for-langflow.py", "w", encoding="utf-8") as f:
        f.write(setup_script)
    print("âœ… è¨­ç½®è…³æœ¬å·²å‰µå»º: setup-astra-for-langflow.py")
    
    # å‰µå»ºä½¿ç”¨æŒ‡å—
    print("ğŸ“ å‰µå»ºä½¿ç”¨æŒ‡å—...")
    usage_guide = integrator.create_usage_guide()
    with open("ASTRA_LANGFLOW_GUIDE.md", "w", encoding="utf-8") as f:
        f.write(usage_guide)
    print("âœ… ä½¿ç”¨æŒ‡å—å·²å‰µå»º: ASTRA_LANGFLOW_GUIDE.md")
    
    print("\nğŸ‰ æ•´åˆå®Œæˆï¼")
    print("=" * 60)
    print("ğŸ“‹ ä¸‹ä¸€æ­¥æ“ä½œ:")
    print("1. é‹è¡Œ: python setup-astra-for-langflow.py")
    print("2. åœ¨ Langflow ä¸­å°å…¥: examples/enhanced-astra-rag-flow.json")
    print("3. æŸ¥çœ‹ä½¿ç”¨æŒ‡å—: ASTRA_LANGFLOW_GUIDE.md")

if __name__ == "__main__":
    main()
