#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Astra DB è¨­ç½®è…³æœ¬
ç‚º Langflow æµç¨‹æº–å‚™ Astra DB æ•¸æ“š
"""

import asyncio
import json
from astrapy import DataAPIClient
from openai import OpenAI

# é…ç½®
ASTRA_DB_ID = "ef4581e5-f997-44ce-8432-e56636786548"
CHATGPT_API_KEY = os.getenv("OPENAI_API_KEY", "YOUR_OPENAI_API_KEY_HERE")

async def setup_astra_for_langflow():
    """ç‚º Langflow è¨­ç½® Astra DB"""
    print("ğŸš€ è¨­ç½® Astra DB ç”¨æ–¼ Langflow")
    print("=" * 50)
    
    # ç²å– API Token
    token = input("è«‹è¼¸å…¥æ‚¨çš„ Astra DB API Token: ").strip()
    if not token:
        print("âŒ éœ€è¦æä¾› API Token")
        return
    
    try:
        # é€£æ¥åˆ° Astra DB
        client = DataAPIClient(token)
        database = client.get_database(ASTRA_DB_ID)
        
        # å‰µå»ºé›†åˆ
        collection_name = "langflow_documents"
        print(f"ğŸ“¦ å‰µå»ºé›†åˆ: {collection_name}")
        
        collection = await database.create_collection(
            collection_name,
            dimension=1536,  # OpenAI åµŒå…¥ç¶­åº¦
            metric="cosine"
        )
        
        # è¨­ç½® OpenAI å®¢æˆ¶ç«¯
        openai_client = OpenAI(api_key=CHATGPT_API_KEY)
        
        # ç¯„ä¾‹æ–‡æª”
        sample_docs = [
            {
                "text": "Langflow æ˜¯ä¸€å€‹é–‹æºçš„ AI æµç¨‹è‡ªå‹•åŒ–å¹³å°ï¼Œå¯ä»¥å¹«åŠ©ç”¨æˆ¶å‰µå»ºè¤‡é›œçš„ AI å·¥ä½œæµç¨‹ã€‚",
                "metadata": {"source": "langflow_docs", "category": "introduction"},
                "timestamp": "2024-01-01T00:00:00Z"
            },
            {
                "text": "Astra DB æ˜¯ DataStax æä¾›çš„å‘é‡æ•¸æ“šåº«æœå‹™ï¼Œå°ˆç‚º AI æ‡‰ç”¨è¨­è¨ˆï¼Œæ”¯æ´é«˜æ•ˆçš„å‘é‡æœç´¢ã€‚",
                "metadata": {"source": "astra_docs", "category": "database"},
                "timestamp": "2024-01-01T00:00:00Z"
            },
            {
                "text": "RAG (Retrieval-Augmented Generation) æ˜¯ä¸€ç¨®çµåˆæª¢ç´¢å’Œç”Ÿæˆçš„ AI æŠ€è¡“ï¼Œå¯ä»¥æé«˜å›ç­”çš„æº–ç¢ºæ€§ã€‚",
                "metadata": {"source": "ai_research", "category": "technique"},
                "timestamp": "2024-01-01T00:00:00Z"
            }
        ]
        
        # ç‚ºæ–‡æª”ç”ŸæˆåµŒå…¥å‘é‡
        print("ğŸ”„ ç”ŸæˆåµŒå…¥å‘é‡...")
        for doc in sample_docs:
            response = openai_client.embeddings.create(
                model="text-embedding-3-small",
                input=doc["text"]
            )
            doc["$vector"] = response.data[0].embedding
        
        # æ’å…¥æ–‡æª”
        print("ğŸ“ æ’å…¥æ–‡æª”åˆ° Astra DB...")
        result = await collection.insert_many(sample_docs)
        print(f"âœ… æˆåŠŸæ’å…¥ {len(sample_docs)} å€‹æ–‡æª”")
        
        print("ğŸ‰ Astra DB è¨­ç½®å®Œæˆï¼")
        print("ç¾åœ¨æ‚¨å¯ä»¥åœ¨ Langflow ä¸­ä½¿ç”¨é€™å€‹å‘é‡æ•¸æ“šåº«äº†ã€‚")
        
    except Exception as e:
        print(f"âŒ è¨­ç½®å¤±æ•—: {e}")

if __name__ == "__main__":
    asyncio.run(setup_astra_for_langflow())
