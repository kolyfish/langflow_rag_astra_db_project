#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Astra DB é›†æˆç¯„ä¾‹
å±•ç¤ºå¦‚ä½•åœ¨ Langflow MCP ä¸­ä½¿ç”¨ Astra DB å‘é‡æ•¸æ“šåº«
"""

import json
import os
import asyncio
from typing import List, Dict, Any, Optional
from datetime import datetime
import numpy as np
import pandas as pd

try:
    from astrapy import DataAPIClient, Collection
    from astrapy.info import CollectionVectorServiceOptions
    from astrapy.constants import VectorMetric
    from openai import OpenAI
    from sentence_transformers import SentenceTransformer
except ImportError as e:
    print(f"âŒ ç¼ºå°‘å¿…è¦çš„å¥—ä»¶: {e}")
    print("è«‹åŸ·è¡Œ: uv pip install astrapy openai sentence-transformers")
    exit(1)

class AstraDBManager:
    """Astra DB ç®¡ç†å™¨"""
    
    def __init__(self, config_path: str = "config/astra-config.json"):
        """åˆå§‹åŒ– Astra DB ç®¡ç†å™¨"""
        self.config = self._load_config(config_path)
        self.client = None
        self.collections = {}
        self.openai_client = None
        self.embedding_model = None
        
    def _load_config(self, config_path: str) -> Dict[str, Any]:
        """è¼‰å…¥é…ç½®æ–‡ä»¶"""
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except FileNotFoundError:
            print(f"âŒ æ‰¾ä¸åˆ°é…ç½®æ–‡ä»¶: {config_path}")
            return {}
        except json.JSONDecodeError as e:
            print(f"âŒ é…ç½®æ–‡ä»¶æ ¼å¼éŒ¯èª¤: {e}")
            return {}
    
    def connect(self, token: str) -> bool:
        """é€£æ¥åˆ° Astra DB"""
        try:
            self.client = DataAPIClient(token)
            database_id = self.config['astra_db']['database_id']
            self.database = self.client.get_database(database_id)
            print(f"âœ… æˆåŠŸé€£æ¥åˆ° Astra DB: {database_id}")
            return True
        except Exception as e:
            print(f"âŒ é€£æ¥ Astra DB å¤±æ•—: {e}")
            return False
    
    def setup_embedding_models(self, openai_api_key: str = None):
        """è¨­ç½®åµŒå…¥æ¨¡å‹"""
        # OpenAI åµŒå…¥æ¨¡å‹
        if openai_api_key:
            self.openai_client = OpenAI(api_key=openai_api_key)
            print("âœ… OpenAI å®¢æˆ¶ç«¯å·²è¨­ç½®")
        
        # Sentence Transformers æ¨¡å‹
        try:
            self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
            print("âœ… Sentence Transformers æ¨¡å‹å·²è¼‰å…¥")
        except Exception as e:
            print(f"âš ï¸  Sentence Transformers æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
    
    async def create_collections(self) -> bool:
        """å‰µå»ºå‘é‡é›†åˆ"""
        try:
            for collection_name, collection_config in self.config['astra_db']['collections'].items():
                print(f"ğŸ“¦ å‰µå»ºé›†åˆ: {collection_name}")
                
                # è¨­ç½®å‘é‡æœå‹™é¸é …
                vector_service = CollectionVectorServiceOptions(
                    provider=collection_config['service']
                )
                
                # å‰µå»ºé›†åˆ
                collection = await self.database.create_collection(
                    collection_config['name'],
                    metric=VectorMetric[collection_config['vector_metric'].upper()],
                    dimension=collection_config['dimension'],
                    service=vector_service
                )
                
                self.collections[collection_name] = collection
                print(f"âœ… é›†åˆ '{collection_name}' å‰µå»ºæˆåŠŸ")
            
            return True
        except Exception as e:
            print(f"âŒ å‰µå»ºé›†åˆå¤±æ•—: {e}")
            return False
    
    def get_embedding_openai(self, text: str) -> List[float]:
        """ä½¿ç”¨ OpenAI ç²å–åµŒå…¥å‘é‡"""
        if not self.openai_client:
            raise ValueError("OpenAI å®¢æˆ¶ç«¯æœªè¨­ç½®")
        
        response = self.openai_client.embeddings.create(
            model="text-embedding-3-small",
            input=text
        )
        return response.data[0].embedding
    
    def get_embedding_sentence_transformers(self, text: str) -> List[float]:
        """ä½¿ç”¨ Sentence Transformers ç²å–åµŒå…¥å‘é‡"""
        if not self.embedding_model:
            raise ValueError("Sentence Transformers æ¨¡å‹æœªè¼‰å…¥")
        
        return self.embedding_model.encode(text).tolist()
    
    async def insert_documents(self, documents: List[Dict[str, Any]], collection_name: str = "documents") -> bool:
        """æ’å…¥æ–‡æª”åˆ°å‘é‡æ•¸æ“šåº«"""
        try:
            if collection_name not in self.collections:
                print(f"âŒ é›†åˆ '{collection_name}' ä¸å­˜åœ¨")
                return False
            
            collection = self.collections[collection_name]
            
            # ç‚ºæ¯å€‹æ–‡æª”ç”ŸæˆåµŒå…¥å‘é‡
            for doc in documents:
                if 'text' in doc:
                    # æ ¹æ“šé›†åˆé…ç½®é¸æ“‡åµŒå…¥æ¨¡å‹
                    collection_config = self.config['astra_db']['collections'][collection_name]
                    if collection_config['service'] == 'openai':
                        doc['$vector'] = self.get_embedding_openai(doc['text'])
                    else:
                        doc['$vector'] = self.get_embedding_sentence_transformers(doc['text'])
            
            # æ‰¹é‡æ’å…¥æ–‡æª”
            result = await collection.insert_many(documents)
            print(f"âœ… æˆåŠŸæ’å…¥ {len(documents)} å€‹æ–‡æª”åˆ°é›†åˆ '{collection_name}'")
            return True
            
        except Exception as e:
            print(f"âŒ æ’å…¥æ–‡æª”å¤±æ•—: {e}")
            return False
    
    async def search_similar(self, query: str, collection_name: str = "documents", limit: int = 5) -> List[Dict[str, Any]]:
        """æœç´¢ç›¸ä¼¼æ–‡æª”"""
        try:
            if collection_name not in self.collections:
                print(f"âŒ é›†åˆ '{collection_name}' ä¸å­˜åœ¨")
                return []
            
            collection = self.collections[collection_name]
            
            # ç”ŸæˆæŸ¥è©¢å‘é‡
            collection_config = self.config['astra_db']['collections'][collection_name]
            if collection_config['service'] == 'openai':
                query_vector = self.get_embedding_openai(query)
            else:
                query_vector = self.get_embedding_sentence_transformers(query)
            
            # åŸ·è¡Œå‘é‡æœç´¢
            results = await collection.vector_find(
                query_vector,
                limit=limit,
                fields=["text", "metadata", "score"]
            )
            
            print(f"ğŸ” æ‰¾åˆ° {len(results)} å€‹ç›¸ä¼¼æ–‡æª”")
            return results
            
        except Exception as e:
            print(f"âŒ æœç´¢å¤±æ•—: {e}")
            return []
    
    async def get_collection_info(self, collection_name: str) -> Dict[str, Any]:
        """ç²å–é›†åˆä¿¡æ¯"""
        try:
            if collection_name not in self.collections:
                return {}
            
            collection = self.collections[collection_name]
            info = await collection.info()
            return info
        except Exception as e:
            print(f"âŒ ç²å–é›†åˆä¿¡æ¯å¤±æ•—: {e}")
            return {}

class LangflowAstraIntegration:
    """Langflow èˆ‡ Astra DB é›†æˆ"""
    
    def __init__(self, astra_manager: AstraDBManager):
        self.astra_manager = astra_manager
    
    async def create_knowledge_base_flow(self) -> Dict[str, Any]:
        """å‰µå»ºçŸ¥è­˜åº«æµç¨‹é…ç½®"""
        flow_config = {
            "name": "Astra DB çŸ¥è­˜åº«æµç¨‹",
            "description": "ä½¿ç”¨ Astra DB å‘é‡æ•¸æ“šåº«çš„çŸ¥è­˜åº«å•ç­”æµç¨‹",
            "data": {
                "nodes": [
                    {
                        "id": "input-1",
                        "type": "TextInput",
                        "position": {"x": 100, "y": 100},
                        "data": {
                            "label": "ç”¨æˆ¶å•é¡Œ",
                            "placeholder": "è«‹è¼¸å…¥æ‚¨çš„å•é¡Œ...",
                            "multiline": True
                        }
                    },
                    {
                        "id": "vector-search",
                        "type": "AstraVectorSearch",
                        "position": {"x": 400, "y": 100},
                        "data": {
                            "label": "å‘é‡æœç´¢",
                            "collection_name": "knowledge_base",
                            "limit": 5,
                            "threshold": 0.7
                        }
                    },
                    {
                        "id": "context-builder",
                        "type": "ContextBuilder",
                        "position": {"x": 700, "y": 100},
                        "data": {
                            "label": "ä¸Šä¸‹æ–‡æ§‹å»ºå™¨",
                            "max_context_length": 2000
                        }
                    },
                    {
                        "id": "llm-processor",
                        "type": "OpenAIChat",
                        "position": {"x": 1000, "y": 100},
                        "data": {
                            "label": "LLM è™•ç†å™¨",
                            "model": "gpt-3.5-turbo",
                            "temperature": 0.7,
                            "max_tokens": 1000,
                            "system_message": "ä½ æ˜¯ä¸€å€‹çŸ¥è­˜åº«åŠ©æ‰‹ï¼ŒåŸºæ–¼æä¾›çš„ä¸Šä¸‹æ–‡å›ç­”ç”¨æˆ¶å•é¡Œã€‚"
                        }
                    },
                    {
                        "id": "output-1",
                        "type": "TextOutput",
                        "position": {"x": 1300, "y": 100},
                        "data": {
                            "label": "å›ç­”è¼¸å‡º"
                        }
                    }
                ],
                "edges": [
                    {
                        "id": "edge-1",
                        "source": "input-1",
                        "target": "vector-search",
                        "sourceHandle": "output",
                        "targetHandle": "input"
                    },
                    {
                        "id": "edge-2",
                        "source": "vector-search",
                        "target": "context-builder",
                        "sourceHandle": "output",
                        "targetHandle": "input"
                    },
                    {
                        "id": "edge-3",
                        "source": "context-builder",
                        "target": "llm-processor",
                        "sourceHandle": "output",
                        "targetHandle": "input"
                    },
                    {
                        "id": "edge-4",
                        "source": "llm-processor",
                        "target": "output-1",
                        "sourceHandle": "output",
                        "targetHandle": "input"
                    }
                ]
            }
        }
        return flow_config

async def main():
    """ä¸»ç¨‹å¼"""
    print("ğŸš€ Astra DB é›†æˆç¯„ä¾‹")
    print("=" * 50)
    
    # å‰µå»º Astra DB ç®¡ç†å™¨
    astra_manager = AstraDBManager()
    
    # æª¢æŸ¥é…ç½®
    if not astra_manager.config:
        print("âŒ é…ç½®æ–‡ä»¶è¼‰å…¥å¤±æ•—")
        return
    
    # ç²å– API Token (éœ€è¦ç”¨æˆ¶æä¾›)
    token = input("è«‹è¼¸å…¥æ‚¨çš„ Astra DB API Token: ").strip()
    if not token:
        print("âŒ éœ€è¦æä¾› API Token")
        return
    
    # é€£æ¥åˆ° Astra DB
    if not astra_manager.connect(token):
        return
    
    # è¨­ç½®åµŒå…¥æ¨¡å‹
    openai_key = input("è«‹è¼¸å…¥ OpenAI API Key (å¯é¸): ").strip()
    astra_manager.setup_embedding_models(openai_key if openai_key else None)
    
    # å‰µå»ºé›†åˆ
    print("\nğŸ“¦ å‰µå»ºå‘é‡é›†åˆ...")
    if not await astra_manager.create_collections():
        return
    
    # ç¯„ä¾‹æ–‡æª”
    sample_documents = [
        {
            "text": "äººå·¥æ™ºæ…§æ˜¯è¨ˆç®—æ©Ÿç§‘å­¸çš„ä¸€å€‹åˆ†æ”¯ï¼Œæ—¨åœ¨å‰µå»ºèƒ½å¤ åŸ·è¡Œé€šå¸¸éœ€è¦äººé¡æ™ºèƒ½çš„ä»»å‹™çš„æ©Ÿå™¨ã€‚",
            "metadata": {"category": "AI", "source": "wikipedia"},
            "timestamp": datetime.now().isoformat()
        },
        {
            "text": "æ©Ÿå™¨å­¸ç¿’æ˜¯äººå·¥æ™ºæ…§çš„ä¸€å€‹å­é ˜åŸŸï¼Œä½¿è¨ˆç®—æ©Ÿèƒ½å¤ åœ¨æ²’æœ‰æ˜ç¢ºç·¨ç¨‹çš„æƒ…æ³ä¸‹å­¸ç¿’å’Œæ”¹é€²ã€‚",
            "metadata": {"category": "ML", "source": "textbook"},
            "timestamp": datetime.now().isoformat()
        },
        {
            "text": "æ·±åº¦å­¸ç¿’æ˜¯æ©Ÿå™¨å­¸ç¿’çš„ä¸€å€‹åˆ†æ”¯ï¼Œä½¿ç”¨äººå·¥ç¥ç¶“ç¶²è·¯ä¾†æ¨¡æ“¬äººè…¦çš„å­¸ç¿’éç¨‹ã€‚",
            "metadata": {"category": "DL", "source": "research_paper"},
            "timestamp": datetime.now().isoformat()
        }
    ]
    
    # æ’å…¥ç¯„ä¾‹æ–‡æª”
    print("\nğŸ“ æ’å…¥ç¯„ä¾‹æ–‡æª”...")
    await astra_manager.insert_documents(sample_documents, "knowledge_base")
    
    # æœç´¢æ¸¬è©¦
    print("\nğŸ” æ¸¬è©¦å‘é‡æœç´¢...")
    query = "ä»€éº¼æ˜¯æ©Ÿå™¨å­¸ç¿’ï¼Ÿ"
    results = await astra_manager.search_similar(query, "knowledge_base", 3)
    
    print(f"\næŸ¥è©¢: {query}")
    print("æœç´¢çµæœ:")
    for i, result in enumerate(results, 1):
        print(f"{i}. {result.get('text', 'N/A')}")
        print(f"   ç›¸ä¼¼åº¦: {result.get('score', 'N/A')}")
        print(f"   å…ƒæ•¸æ“š: {result.get('metadata', {})}")
        print()
    
    # å‰µå»º Langflow é›†æˆ
    integration = LangflowAstraIntegration(astra_manager)
    flow_config = await integration.create_knowledge_base_flow()
    
    # ä¿å­˜æµç¨‹é…ç½®
    with open("examples/astra-knowledge-flow.json", "w", encoding="utf-8") as f:
        json.dump(flow_config, f, ensure_ascii=False, indent=2)
    
    print("âœ… Astra DB é›†æˆç¯„ä¾‹å®Œæˆï¼")
    print("ğŸ“ æµç¨‹é…ç½®å·²ä¿å­˜åˆ°: examples/astra-knowledge-flow.json")

if __name__ == "__main__":
    asyncio.run(main())
